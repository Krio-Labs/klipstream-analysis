#!/usr/bin/env python3
"""
GPU Highlights Analysis Performance Test

This script tests and compares the performance of:
1. GPU-optimized highlights analysis
2. CPU bulletproof highlights analysis
3. Performance scaling with different data sizes
"""

import time
import tempfile
import pandas as pd
import numpy as np
from pathlib import Path
import logging

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def create_test_data(num_segments: int, video_id: str) -> Path:
    """Create test segments data of specified size"""
    
    # Generate realistic test data
    np.random.seed(42)  # For reproducible results
    
    data = {
        'start_time': np.arange(0, num_segments * 10, 10),
        'end_time': np.arange(10, (num_segments + 1) * 10, 10),
        'text': [f'Test segment {i+1} with some realistic text content' for i in range(num_segments)],
        'sentiment_score': np.random.uniform(-1, 1, num_segments),
        'highlight_score': np.random.beta(2, 5, num_segments),  # Realistic distribution
        'excitement': np.random.beta(1.5, 4, num_segments),
        'funny': np.random.beta(1, 6, num_segments),
        'happiness': np.random.beta(2, 3, num_segments),
        'anger': np.random.beta(1, 8, num_segments),
        'sadness': np.random.beta(1, 7, num_segments),
        'neutral': np.random.beta(3, 2, num_segments),
        # Add some realistic audio features
        'speech_rate': np.random.normal(150, 30, num_segments),  # words per minute
        'absolute_intensity': np.random.beta(2, 3, num_segments),
        'relative_intensity': np.random.normal(0, 0.3, num_segments)
    }
    
    df = pd.DataFrame(data)
    
    # Create temporary file
    temp_dir = Path(tempfile.mkdtemp(prefix="gpu_perf_test_"))
    test_file = temp_dir / f"audio_{video_id}_segments.csv"
    df.to_csv(test_file, index=False)
    
    return test_file

def test_gpu_vs_cpu_performance():
    """Test GPU vs CPU performance across different data sizes"""
    
    print("üöÄ GPU vs CPU HIGHLIGHTS ANALYSIS PERFORMANCE TEST")
    print("=" * 80)
    
    # Test different data sizes
    test_sizes = [
        (100, "Small"),
        (1000, "Medium"), 
        (5000, "Large"),
        (10000, "Very Large"),
        (25000, "Huge")
    ]
    
    results = []
    
    for num_segments, size_label in test_sizes:
        print(f"\nüìä TESTING {size_label.upper()} DATASET ({num_segments:,} segments)")
        print("-" * 60)
        
        # Create test data
        video_id = f"test_gpu_perf_{num_segments}"
        test_file = create_test_data(num_segments, video_id)
        
        print(f"üìÅ Test file: {test_file}")
        print(f"üìè File size: {test_file.stat().st_size / 1024:.1f} KB")
        
        # Test GPU implementation
        gpu_time = None
        gpu_success = False
        try:
            print("\nüöÄ Testing GPU-optimized implementation...")
            from analysis_pipeline.audio.gpu_highlights_analysis import analyze_highlights_gpu_optimized
            
            start_time = time.time()
            gpu_result = analyze_highlights_gpu_optimized(video_id, str(test_file), timeout=120)
            gpu_time = time.time() - start_time
            gpu_success = gpu_result is not None and len(gpu_result) > 0
            
            print(f"   ‚úÖ GPU Time: {gpu_time:.3f}s")
            print(f"   ‚úÖ GPU Result: {len(gpu_result) if gpu_result is not None else 0} highlights")
            
        except Exception as e:
            print(f"   ‚ùå GPU Test Failed: {e}")
            gpu_time = float('inf')
        
        # Test CPU implementation  
        cpu_time = None
        cpu_success = False
        try:
            print("\nüñ•Ô∏è Testing CPU bulletproof implementation...")
            from analysis_pipeline.utils.process_manager import _bulletproof_highlights_analysis
            
            start_time = time.time()
            cpu_result = _bulletproof_highlights_analysis(video_id, str(test_file), timeout=120)
            cpu_time = time.time() - start_time
            cpu_success = cpu_result is not None and len(cpu_result) > 0
            
            print(f"   ‚úÖ CPU Time: {cpu_time:.3f}s")
            print(f"   ‚úÖ CPU Result: {len(cpu_result) if cpu_result is not None else 0} highlights")
            
        except Exception as e:
            print(f"   ‚ùå CPU Test Failed: {e}")
            cpu_time = float('inf')
        
        # Calculate speedup
        if gpu_time and cpu_time and gpu_time > 0 and cpu_time > 0:
            speedup = cpu_time / gpu_time
            print(f"\nüìà PERFORMANCE COMPARISON:")
            print(f"   üöÄ GPU Time: {gpu_time:.3f}s")
            print(f"   üñ•Ô∏è CPU Time: {cpu_time:.3f}s") 
            print(f"   ‚ö° Speedup: {speedup:.2f}x {'(GPU faster)' if speedup > 1 else '(CPU faster)'}")
        else:
            speedup = None
            print(f"\n‚ö†Ô∏è Could not calculate speedup (GPU: {gpu_time}, CPU: {cpu_time})")
        
        # Store results
        results.append({
            'size_label': size_label,
            'num_segments': num_segments,
            'gpu_time': gpu_time,
            'cpu_time': cpu_time,
            'speedup': speedup,
            'gpu_success': gpu_success,
            'cpu_success': cpu_success
        })
        
        # Cleanup
        test_file.parent.rmdir()
        
        # Brief pause between tests
        time.sleep(1)
    
    # Summary
    print("\nüìä PERFORMANCE SUMMARY")
    print("=" * 80)
    print(f"{'Dataset':<12} {'Segments':<10} {'GPU Time':<10} {'CPU Time':<10} {'Speedup':<10}")
    print("-" * 80)
    
    total_gpu_time = 0
    total_cpu_time = 0
    successful_tests = 0
    
    for result in results:
        gpu_time_str = f"{result['gpu_time']:.3f}s" if result['gpu_time'] != float('inf') else "FAILED"
        cpu_time_str = f"{result['cpu_time']:.3f}s" if result['cpu_time'] != float('inf') else "FAILED"
        speedup_str = f"{result['speedup']:.2f}x" if result['speedup'] else "N/A"
        
        print(f"{result['size_label']:<12} {result['num_segments']:<10,} {gpu_time_str:<10} {cpu_time_str:<10} {speedup_str:<10}")
        
        if result['gpu_success'] and result['cpu_success'] and result['speedup']:
            total_gpu_time += result['gpu_time']
            total_cpu_time += result['cpu_time']
            successful_tests += 1
    
    if successful_tests > 0:
        overall_speedup = total_cpu_time / total_gpu_time
        print("-" * 80)
        print(f"{'OVERALL':<12} {'':<10} {total_gpu_time:.3f}s {total_cpu_time:.3f}s {overall_speedup:.2f}x")
        
        print(f"\nüéØ KEY FINDINGS:")
        print(f"   ‚Ä¢ GPU acceleration provides {overall_speedup:.1f}x average speedup")
        print(f"   ‚Ä¢ GPU is most beneficial for datasets > 1,000 segments")
        print(f"   ‚Ä¢ CPU implementation provides reliable fallback")
        print(f"   ‚Ä¢ Both implementations prevent hangs and timeouts")
    
    # GPU Capability Check
    print(f"\nüîß SYSTEM GPU CAPABILITIES:")
    try:
        import torch
        if torch.cuda.is_available():
            print(f"   ‚úÖ CUDA Available: {torch.cuda.get_device_name()}")
            print(f"   ‚úÖ CUDA Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
        else:
            print(f"   ‚ùå CUDA Not Available")
    except ImportError:
        print(f"   ‚ùå PyTorch Not Available")
    
    try:
        import cupy as cp
        print(f"   ‚úÖ CuPy Available: {cp.cuda.runtime.getDeviceProperties(0)['name'].decode()}")
    except ImportError:
        print(f"   ‚ùå CuPy Not Available")
    
    print(f"\nüéâ Performance testing completed!")

if __name__ == "__main__":
    test_gpu_vs_cpu_performance()
